# This file defines an experiment creating neural connections using a snap paradigm.
# Snap paradigm doesn't grow neuron parts gradually, but rather "snaps" them into connections.

# Snap paradigms make heavy use of probabilities. All probabilities are given in the form of
# floating point values between 0.0 and 1.0, representing 0% chance of happening an 100%, respectively.

BrainParadigm: Snap

# By default, input neurons act much like processing neurons, except the use environmental inputs
# instead of other neuron inputs.  If passthrough neurons are set, there will be one input neuron
# for each possible environmental input and it will exactly match the input from the environment
# with no processing.
UsePassthroughInputNeurons: False

# Overall probability is a probability multiplied by all other probabilities before being applied.
# It can be thought of as a mirror to a standard artificial neural network's learning rate in that
# it will slow or speed the full adaptation process.
OverallProbability: [1.0, 1.0]

# Dynamic overall probability is used to slow down change as the brain gets closer to success
# and speed up changes as it gets further from success. At the end of each run, the run's success
# value is set to [1.0 - (score / maxScore)]. These variables define how it is applied.
# ADD - Dynamic probability is added to overall probability.
# SOLO - Dynamic probability replaces overall probability.
# MULTIPLY - Overall probability is multpiled by the dynamic probability.
# UNUSED - Overall probability is not changed by dynamic probability. 
DynamicProbabilityMultiplier: [1.0, 1.0]
DynamicProbabilityApplication:
 - ADD
 #- SOLO
 #- MULTIPLY
 #- UNUSED

# The snap paradigm tracks events and allows for a selection of adaptive processes to occur
# during each: Step, Output neuron gets input, end of run, too long since input without producing
#              output.
# Step - Every brain time-step.
# Output - Every time an output neuron gets input.
#  - These events are separated into positive and negative changes. 
#  - Positive changes occur when the neuron that SHOULD fire gets input from a processing neuron.
#  - Negative changes occur when the neuron that SHOULD NOT fire gets input from a processing neuron. 
# Run - At the end of a run through the full environment (environment reaches done state).
# Too long - This is here to ensure that the brain isn't caught in an endless loop, never producing
#            output. These events should encourage the output neurons to fire more often.

# Care should be taken when considering the percent chances of events at each given time.
# There will likely be many steps per output and possibly hundreds of outputs per run.
# An event that happens 5% of the time for each step will likel happen more often than 100% of the
# time for a run.

# Snap paradigm uses three neuron types: Input, Processing, and Output.
# The primary difference between them is in what connections their dendrites can make.
# Input neurons can connect to the inputs from the environment (observation).
# Processing neurons can connect to input neurons or other processing neurons.
# Output neurons can only connect to processing neurons. There will only ever be
# exactly as many output neurons as there are brain actions to take.

# "Cascade" refers to how an event propogates through the neurons that "caused" it.
# For instance, if an output neuron fires on step 5, if the event cascades, it will
# apply to the processing neurons connected to it which fired on step 4. The name of
# the variable will indicate to which neurons the event will cascade. Cascade probability
# indicates the percentage multiplier to apply to the chance that it occurs in the next
# neuron in the cascade line.

# -------------------------------------
# ------------ Non-Events -------------
# -------------------------------------
# Variables that don't apply to a specific event.

# Cumulative input range: The number of timesteps back that a neuron uses inputs
# to calculate if it fires or not. 1 indicates that only the previous step counts,
# X means the previous X steps. Neuron reset indicates that it zeroes out its input
# when firing. If input range is high, should consider setting resets to True to avoid
# the brain having a seizure.
NeuronAccumulateDuration: [4, 4]
NeuronResetInputOnFiring: Mutable
NeuronFiresResetAfterOutput: True
NeuronMaximumAge: [5000, 5000]  # Beyond this number, age is assumed to be equal to this value.

# When a change is made to a dendrite's weight, this is how much it changes:
DendriteWeightChange: [0.0, 0.0]
MinimumDendriteWeight: [0.0, 0.0]
MaximumDendriteWeight: [1.0, 1.0]  # Make sure this is high enough to get input neurons to fire.
DendriteStartingWeight: [1.0, 1.0]  # Make sure this is high enough to get input neurons to fire.
MinimumDendritesPerNeuron: [3, 3]
MaximumDendritesPerNeuron: [25, 25]
StartingDendritesPerNeuron: [15, 15]

# Base processing neuron count is used as part of equations that decide to create
# or destroy neurons based on a ratio of (X / base) or (base / X):
BaseProcessingNeuronCount: [500, 500]
StartingInputNeuronCount: [15, 15]  # REMOVE LATER? INPUT COUNT BASED ON USING ALL INPUTS?
StartingProcessingNeuronCount: [90, 90]

# Absolute maximums to prevent effective infinite loops. Stored as lists to make
# use of preexisting retrieval functions:
MaximumProcessingNeuronCount: [5000, 5000]
MaximumInputNeuronToInputsRatio: [10, 10]

NeuronFireThreshold: [1.0, 1.0]

# The number of processing steps the brain can take without producing output
# before the brain makes changes and tries again.
ProcessingStepsAllowed: [5, 5]

# -------------------------------------
# --------- Input Processing ----------
# -------------------------------------
# Three types (for now): No-change, buckets, and negative value add. The purpose of this processing is
#                        to give all of the information to the brain without using negative values since
#                        (for now), there are no negative weights.
# No change: The inputs are passed forward exactly as is. This can pass forward negative values and thus
#            shouldn't be used in environments where important information can be provided as a negative.
#            MANY PLACES IN THE CODE MAKE THE ASSUMPTION THAT "INPUT" MEANS VALUE > 0.0
# Buckets: X buckets are created for each input, spread across its possible values.
#          The bucket corresponding to that input's value will be set to 1.0 as a brain input.
# Negative value add: There will be 2x the number of inputs passed to the brain. 1 matching the
#                     no-change value when it is positev and 0 when it is negative. The other
#                     matching the absolute value of the input when it is negative and zero when
#                     it is positive.

# CARTPOLE:
InputOutputProcessing:
  Type: Buckets # NoChange, Buckets, NegativeValueAdd
  ObservationSize: 4
  ObsRanges: [[-2.4, 2.4], [-1.0, 1.0], [-0.3, 0.3], [-1.0, 1.0]] # Only used in bucket mode
  UseDynamicObsRanges: True # Overrides above bucket ranges with those from the TrainingCSV.
  BucketsPerInput: [150, 150, 150, 150] # Only used in bucket or HDC mode, buckets per input
  ActionSize: 2

# LunarLander
# InputOutputProcessing:
  # Observations / Inputs
  # Type: Buckets # NoChange, Buckets, NegativeValueAdd    
  # ObservationSize: 8
  # ObsRanges: [[-2.5, 2.5], [-2.5, 2.5], [-10.0, 10.0], [-10.0, 10.0], [-6.2831855, 6.2831855], [-10.0, 10.0], [0, 1], [0, 1]]
  # UseDynamicObsRanges: True # Overrides above bucket ranges with those from the TrainingCSV.
  # BucketsPerInput: [3000, 3000, 3000, 3000, 3000, 3000, 50, 50]
  # ActionSize: 4
  
  # Actions / Outputs:
  # ActionSize: 4
  # ActionRanges: [[-1.0, 1.0], [-1.0, 1.0]]
  # BucketsPerOutput: [500, 500]

  # If not blank, this indicates a CSV file expected to have 1 observation and 1 action per row.
  # If this file name is provided, the observation ranges will be overriden by the values
  # found in it.
  TrainingCSV: C:\\Sync\\CGP_CPP_TestApp\\samplePython\\ppoSageLLD_1000.csv

EnvironmentDetails:
  ActionSize: [4, 4] # Stored as a list to make use of general retrieval functions in JBrainFactory.

# Hyperdimensional Computing Mode - More strongly mimic how HDC handles inputs. HDC more closely
# resembles how brains processing input and is thus very noisy-data tolerant. HDC mode only
# works with Bucket input processing and will disable many of the below options.
# HDC mode dramatically changes how the brain grow and how training should proceed.
# Therefore, "Active" below should be True or False, not mutable.
HDCMode:
  Active: True
  MinimumDeleteDistance: [0, 0]  # Single distance for single output or summed distance for multiple outputs.
  TrainingLearningMode:
   - FULL
   - WRONG

# -------------------------------------
# ------------ StepEvents -------------
# -------------------------------------
StepEvents:
  CreateProcessingNeuron:
    StartingChance: [0.0, 0.0]
    BaseOverCountRatioMultiplier: [0.0, 0.0]

  DestroyProcessingNeuron:
    StartingChance: [0.0, 0.0]
    CountOverBaseRatioMultiplier: [0.0, 0.0]

  CreateInputNeuron:
    StartingChance: [0.0, 0.0]
    ObservationSizeOverInputNeuronCountMultiplier: [0.0, 0.0]

  DestroyInputNeuron:
    StartingChance: [0.0, 0.0]
    InputNeuronCountOverObservationSizeMultiplier: [0.0, 0.0]

# -------------------------------------
# -------- OutputNeuronEvents ---------
# -------------------------------------
OutputEvents:  
  # Correct output neuron got input from processing neuron:
  OutputPositive:
    # The chance that any given event triggered by an output neuron that should have fired
    # cascades to processing neurons and potentially input neurons.
    CascadeProbability: [0.0, 0.0]

    # Increase the weight of inputs it got from the processing neuron(s) that fired just
    # before it did: 
    FiredInSequence_IncreaseDendriteWeightFromInput: [0.0, 0.0]

    # Target processing neuron fired directly before the output neuron, but the
    # output neuron does not have any connection to it.
    NoConnectionButFiredInSequence_CreateConnection: [0.0, 0.0]
    # No favoring factors, yet. Also, no check against connection to ourselves.

  # Weights tick down gradually. If they're never used, they eventually die off.
  DecreaseAllDendriteWeights:
    DecreaseAmount: [0.0, 0.0]

  # Wrong output neuron got input from processing neuron:
  OutputNegative:
    CascadeProbability: [0.0, 0.0]
    FiredInSequence_DecreaseDendriteWeightFromInput: [0.0, 0.0]
    FiredInSequence_BreakConnection: [0.0, 0.0]

  OutputNeuronFired:
    CorrectNeuron:
      IncreaseAllUsedDendriteConnections:
        ChangeAmount: [1.0, 1.0]
      UnusedInput:
        DecreaseWeight: [0.5, 0.5]
        BreakConnection: [0.5, 0.5]
    WrongNeuron:
      DecreaseAllUsedDendriteConnections:
        ChangeAmount: [0.5, 0.5]
      CreatePureProcessingNeuron_CorrectOutput: [1.0, 1.0]

# -------------------------------------
# ------------ RunEvents --------------
# -------------------------------------
RunEvents:  
  CreateProcessingNeuron:
    StartingChance: [0.0, 0.0]
    BaseOverCountRatioMultiplier: [0.0, 0.0]

  DestroyProcessingNeuron:
    StartingChance: [0.0, 0.0]
    CountOverBaseRatioMultiplier: [0.0, 0.0]

  CreateInputNeuron:
    StartingChance: [0.0, 0.0]
    ObservationSizeOverInputNeuronCountMultiplier: [0.0, 0.0]

  DestroyInputNeuron:
    StartingChance: [0.0, 0.0]
    InputNeuronCountOverObservationSizeMultiplier: [0.0, 0.0]

# Weight factors:
WeightDestroyProcessingNeuron:
  FavorNeuronsWithFewerConnections: True
  FavorYoungerNeurons: True
  #FaverLessPureNeurons: True

# -------------------------------------
# ------ Too Long Without Output ------
# -------------------------------------
# These events fire if the brain was given X time steps and no output neuron fired.
# These weights are heavy-handed to get the brain into a position where its more subtle
# adaptive factors can take over. Each of these chances is run on every valid target.
NoOutputEvents:
  IncreaseInputDendriteWeight: [1.0, 1.0]
  AddProcessingNeuronDendrite: [0.0, 0.0]
  IncreaseProcessingNeuronDendriteWeight: [0.0, 0.0]
  AddOutputNeuronDendrite: [0.1, 0.1]
  IncreaseOutputNeuronDendriteWeight: [0.1, 0.1]
  CreateProcessingNeuron: [0.0, 0.0]
  CreatePureProcessingNeuron_CorrectOutput: [1.0, 1.0]

Experiment:
  MainDataDirectory: C:\Sync\PhD\ImitationData\CartPole\BrainTests\
  ExperimentName: FullExperimentTest

  # If "None", the directory for this experiment will be dynamically generated and the
  # experiment will start. If not "None", this is expected to be the absolute path to
  # the directory of an experiment in progress. Setting this value to a folder will
  # make all other parameters in this yaml file irrelevant. A copy of the yaml which
  # described the experiment is in the folder and will be used.
  # It is important that the path here ends with a backslash.
  ExperimentDirectory: None

  # Some reward functions base their grade on only the scores during the 
  # test trials, so we separate from training trials:
  TrainTrials: 50 # Ignored if training via CSV file
  TestTrials: 25  # At least 1 to prevent division by 0 problems elsewhere
  MaximumEpochs: 10
 
  StartingPopulationSize: 1

  # Not actually a maximum, but if reward reaches this, the experiment ends.
  MaximumReward: 1.9
  
  # The reward at which we will add a group of random brains to the population
  # because the current population is performing very poorly:
  PopulationInfusionReward: 0.0
  PopulationInfusionSize: 10
 
  # Differing reward calculations and the multipliers that should be applied
  # to them as they are included as part of the final calculation.
  # Not the most extensible way to do this, but this section will provide a
  # multiplier for each new reward type. These reward equations will be
  # hardcoded in the test app. It is important to take this section of rewards
  # into account when setting the maximum reward above:
  
  # Added to the score every time the brain has a no-output event during testing.
  Reward_TestNoOutput: -0.1
  
  # Multiplied by the percent of time the brain matches good output during the test runs.
  Reward_TestPercentGoodOutput: 1.0 

  # Multiplied by the percent of time the brain matches bad output during the test runs.
  Reward_TestPercentBadOutput: -1.0
  
  # Multiplied by the percentage of the best score the maximum in the test trials hits:
  Reward_TestMaxScorePercent: 1.0

  # Multiplied by the percentage of the (best - min) score in the test trials:
  Reward_TestBestMinusMin: -1.0

  # Multiplied by the ratio of (countProcNeuronsCreated + countProcNeuronsDestroyed) / (2* total steps)
  # to penalize excessive processor neuron creation and destruction. Equivalent value for input neurons:
  Reward_TestProcessingNeuronChurn: -0.6
  Reward_TestInputNeuronChurn: -0.6

  # Reward for the slope value of an overall trendline. This includes ALL reward values,
  # not just test. It is set high because for large numbers of training/testing runs, even
  # great learning grows slowly.
  Reward_TrendlineScoreSlope: 5.0

